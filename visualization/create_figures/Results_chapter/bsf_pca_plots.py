'''
A script where we use PCA to visualize the features generated by a feature extractor. Now with various feature extractors.

Usage: Just run the script. It will load the features from the CSV files and create PCA plots for each of them.
'''

#%%
# SETUP
import pandas as pd

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

def make_pca_plot(features_df, title, fig_name):
    # CREATE PCA PLOT
    pca = PCA(n_components=2)
    reduced_features = pca.fit_transform(features_df.iloc[:, :-2])
    
    Supra_features = reduced_features[features_df["loc_label"] == 0]
    Infra_features = reduced_features[features_df["loc_label"] == 1]

    print("Amount of Supra features: ", Supra_features.shape)
    print("Amount of Infra features: ", Infra_features.shape)
    print()
    print("Amount of Glioma features: ", features_df[features_df["diag_label"] == 0].shape)
    print("Amount of Ependymoma features: ", features_df[features_df["diag_label"] == 1].shape)
    print("Amount of Medulloblastoma features: ", features_df[features_df["diag_label"] == 2].shape)
    
    features_Supra = features_df[features_df["loc_label"] == 0]
    features_Infra = features_df[features_df["loc_label"] == 1]

    # map colors
    color_map = {0: 'green', 1: 'red', 2: 'blue'}
    Supra_colors = [color_map[label] for label in features_Supra["diag_label"]]
    Infra_colors = [color_map[label] for label in features_Infra["diag_label"]]

    # New way of plotting, using red, green and blue.
    plt.scatter(x=Supra_features[:,0], y=Supra_features[:,1], c=Supra_colors, marker="x", s=35) #Need to put in color legend at some point.
    plt.scatter(x=Infra_features[:,0], y=Infra_features[:,1], c=Infra_colors, marker="o")

    # # Old way of plotting, that colors with the default colors.
    # plt.scatter(x=Supra_features[:,0], y=Supra_features[:,1], c=features_Supra["diag_label"], marker="x", s=30) #Need to put in color legend at some point.
    # plt.scatter(x=Infra_features[:,0], y=Infra_features[:,1], c=features_Infra["diag_label"], marker="o")
    
    
    #plt.scatter(x=reduced_features[:, 0], y=reduced_features[:, 1], c=features_df["diag_label"])
    #plt.scatter(x=reduced_features[:, 0], y=reduced_features[:, 1], c=features_df["loc_label"])
    
    
    plt.xlabel("PC 1", fontsize=20)
    plt.ylabel("PC 2", fontsize=20)
    ax = plt.gca()
    #ax.set_aspect("equal")
    plt.suptitle(title, fontsize=20)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.suptitle(title, fontsize=20)

    plt.grid()
    plt.tight_layout()
    plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/"+fig_name+".png")


    # scale_factor = 10*pca.explained_variance_
    # plt.arrow(0,0,
    #           scale_factor[0]*pca.components_[0,0],scale_factor[0]*pca.components_[0,1],
    #           width=0.02) # PC1
    # plt.arrow(0,0,
    #           scale_factor[1]*pca.components_[1,0],scale_factor[1]*pca.components_[1,1],
    #           width=0.02) # PC2
    plt.show()


#%%

features_t1gd_and_t2_df = pd.read_csv("/home/simjo484/master_thesis/Master_Thesis/visualization/create_figures/Results_chapter/BSF_generated_features/bsf_features_t1gd_and_t2.csv")
features_t1gd_df = pd.read_csv("/home/simjo484/master_thesis/Master_Thesis/visualization/create_figures/Results_chapter/BSF_generated_features/bsf_features_t1gd.csv")
features_t2_df = pd.read_csv("/home/simjo484/master_thesis/Master_Thesis/visualization/create_figures/Results_chapter/BSF_generated_features/bsf_features_t2.csv")



make_pca_plot(features_t1gd_and_t2_df, title="Features from T1W-GD and T2W sequences", fig_name="t1gd_and_t2_pca_features")
make_pca_plot(features_t1gd_df, title="Features from T1W-GD sequences", fig_name="t1gd_pca_features")
make_pca_plot(features_t2_df, title="Features from T2W sequences", fig_name="t2_pca_features")



#%%


# #%%
# # SETUP
# import torch
# import os

# os.chdir("/home/simjo484/master_thesis/Master_Thesis")
# from utils import EmbedSwinUNETR, get_loader

# os.chdir("/home/simjo484/master_thesis/Master_Thesis/BSF_finetuning")
# #from bsf_data_utils import get_loader


# import matplotlib.pyplot as plt
# import argparse

# from itertools import islice

# import numpy as np

# # Arguments
# class Args(argparse.Namespace):
#     logdir = ""
#     optim_lr = 1e-4
#     reg_weight = 1e-5
#     roi_x = 128
#     roi_y = 128
#     roi_z = 128
#     distributed = False
#     workers = 18
#     data_dir='/local/data2/simjo484/BRATScommon/BRATS21/'
#     json_list = "./jsons/brats21_folds.json"
#     fold = 4
#     test_mode = False
#     batch_size = 1
#     debug_mode = False
#     device = "cuda"
#     cl_device = "cuda"
#     pp_device = "cpu"
#     data_aug_prob = 0.3

# args = Args()

# #%%
# # LOAD MODEL
# sequences = "t1gd_and_t2" #"t1gd_and_t2"
# label_column = "loc_label"

# if sequences == "t2":
#     # T2W Loader
#     loader, loss = get_loader(args, label_column = label_column, seq_types="T2W")

#     # T2W Model
#     model = EmbedSwinUNETR()
#     model.to("cuda")
#     model.load_state_dict(torch.load("/local/data2/simjo484/Training_outputs/BSF_finetuning/runs/2025-03-27-13:20:53 (t2)/model_final.pt", map_location="cuda")["state_dict"])
# elif sequences == "t1gd":
#     # T1W-GD Loader
#     loader, loss = get_loader(args, label_column = label_column, seq_types="T1W-GD")

#     # T1W-GD Model
#     model = EmbedSwinUNETR()
#     model.to("cuda")
#     model.load_state_dict(torch.load("/local/data2/simjo484/Training_outputs/BSF_finetuning/runs_t1gd/2025-04-07-10:40:33/model_final.pt", map_location="cuda")["state_dict"])
# elif sequences == "t1gd_and_t2":
#     # T1W-GD and T2W Loader
#     loader, loss = get_loader(args, label_column = label_column, seq_types="T1W-GD_T2W")

#     # T1W-GD and T2W Model
#     model = EmbedSwinUNETR()
#     model.to("cuda")
#     model.load_state_dict(torch.load("/local/data2/simjo484/Training_outputs/BSF_finetuning/runs_t1gd_and_t2/2025-03-28-23:14:58/model_final.pt", map_location="cuda")["state_dict"])



# # CREATE DATA MATRIX
# features = []
# labels = []

# for id, batch_data in enumerate(loader[0]):
#     data, target = batch_data["images"].to(args.device), batch_data["label"].to(args.device)
#     #print(f"DATA SHAPE: {data.shape}")

#     #data = data[0]
#     #print(f"DATA SHAPE: {data.shape}")

#     x = model(data)

#     batch_size = args.batch_size
#     #x = torch.flatten(x)
#     x = torch.nn.AvgPool3d((4,4,4))(x).view(batch_size, 768)[0] # The [0] is to remove the 1 in the shape from batch size 1.

#     features.append(x.detach().to("cpu"))
#     labels.append(target.to("cpu"))

# features = np.array(features)
# labels = np.array(labels)
# print(f"FEATURES HAVE DIMS: {features.shape}")
# print(f"LABELS HAVE DIMS: {labels.shape}")

# #%%
# # CREATE PCA PLOT
# from sklearn.decomposition import PCA

# pca = PCA(n_components=2)
# reduced_features = pca.fit_transform(features)
# print(pca.explained_variance_ratio_)


# plt.scatter(x=reduced_features[:,0], y=reduced_features[:,1], c=labels)
# plt.xlabel("PC1")
# plt.ylabel("PC2")
# ax = plt.gca()
# #ax.set_aspect("equal")

# if sequences == "t2":
#     plt.suptitle("Features from T2W images, colored by location")
#     plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/t2_pca_features.png")
# if sequences == "t1gd":
#     plt.suptitle("Features from T1W-GD images, colored by location")
#     plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/t1gd_pca_features.png")
# if sequences == "t1gd_and_t2":
#     plt.suptitle("Features from fused T1W-GD and T2W images, colored by location")
#     plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/t1gd_and_t2_pca_features.png")


# plt.show()
# %%
