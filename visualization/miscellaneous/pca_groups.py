'''
I found seemingly two groups in the PCA plot of the features generated by the T1GD and T2 feature extractor.
These groups did not correlate to diagnosis, and neither to tumour location. So I will investigate if they
relate to age or sex. So first I will have to attach that metadata to the training observations.
'''

#%%
# SETUP
import pandas as pd
from itertools import islice
import pickle
import os
os.chdir("/home/simjo484/master_thesis/Master_Thesis")
from utils import unique

# LOAD DATA
data_raw = pd.read_excel("/local/data1/simjo484/mt_data/all_data/MRI/MRI_summary_extended_simon.xlsx")

meta_root = "/local/data1/simjo484/mt_data/all_data/MRI/simon/"
with open(meta_root+"train_df.pkl", "rb") as f:
    train_df = pickle.load(f)

with open(meta_root+"valid_df.pkl", "rb") as f:
    valid_df = pickle.load(f)

with open(meta_root+"test_df.pkl", "rb") as f:
    test_df = pickle.load(f)



# Create codings for the tumour locations
supra_locations = [
    "Frontal Lobe",
    "Optic Pathway,Suprasellar/Hypothalamic/Pituitary",
    "Thalamus",
    "Temporal Lobe",
    "Frontal Lobe,Parietal Lobe",
    "Thalamus,Ventricles",
    "Occipital Lobe",
    "Occipital Lobe,Temporal Lobe",
    "Hippocampus",
    "Suprasellar/Hypothalamic/Pituitary",
    "Optic Pathway,Suprasellar/Hypothalamic/Pituitary,Thalamus",
    "Optic Pathway,Other locations NOS,Suprasellar/Hypothalamic/Pituitary,Thalamus",
    "Suprasellar/Hypothalamic/Pituitary,Thalamus",
    "Parietal Lobe",
    "Basal Ganglia,Thalamus",
    "Optic Pathway,Suprasellar/Hypothalamic/Pituitary,Ventricles",
    "Basal Ganglia,Other locations NOS,Temporal Lobe,Thalamus",
    "Parietal Lobe,Temporal Lobe",
    "Other locations NOS,Pineal Gland,Thalamus",
    "Temporal Lobe,Thalamus",
    "Other locations NOS,Suprasellar/Hypothalamic/Pituitary,Ventricles",
    "Basal Ganglia,Suprasellar/Hypothalamic/Pituitary,Thalamus",
    "Frontal Lobe,Temporal Lobe",
    "Frontal Lobe,Parietal Lobe,Temporal Lobe"]

infra_locations = [
    "Cerebellum/Posterior Fossa",
    "Cerebellum/Posterior Fossa,Meninges/Dura,Spinal Cord- Cervical,Spinal Cord- Thoracic,Ventricles",
    "Cerebellum/Posterior Fossa,Optic Pathway,Suprasellar/Hypothalamic/Pituitary,Thalamus",
    "Brain Stem-Medulla,Brain Stem- Midbrain/Tectum,Cerebellum/Posterior Fossa",
    "Cerebellum/Posterior Fossa,Meninges/Dura",
    "Brain Stem-Medulla,Cerebellum/Posterior Fossa,Ventricles",
    "Cerebellum/Posterior Fossa,Optic Pathway",
    "Cerebellum/Posterior Fossa,Ventricles",
    "Brain Stem- Midbrain/Tectum,Cerebellum/Posterior Fossa,Thalamus",
    "Cerebellum/Posterior Fossa,Other locations NOS",
    "Brain Stem- Pons,Cerebellum/Posterior Fossa",
    "Cerebellum/Posterior Fossa,Meninges/Dura,Optic Pathway,Other locations NOS,Suprasellar/Hypothalamic/Pituitary,Ventricles",
    "Cerebellum/Posterior Fossa,Meninges/Dura,Spinal Cord- Cervical,Spinal Cord- Lumbar/Thecal Sac,Spinal Cord- Thoracic",
    "Brain Stem- Midbrain/Tectum",
    "Brain Stem-Medulla,Brain Stem- Pons",
    "Brain Stem- Midbrain/Tectum,Thalamus",
    "Brain Stem- Pons"]

mixed_locations = [
    "Cerebellum/Posterior Fossa, Frontal Lobe",
    "Cerebellum/Posterior Fossa,Frontal Lobe",
    "Basal Ganglia,Cerebellum/Posterior Fossa,Occipital Lobe,Other locations NOS,Parietal Lobe,Temporal Lobe,Thalamus",
    "Brain Stem- Midbrain/Tectum,Temporal Lobe,Thalamus",
    "Meninges/Dura,Spinal Cord- Lumbar/Thecal Sac,Suprasellar/Hypothalamic/Pituitary",
    "Basal Ganglia,Frontal Lobe,Meninges/Dura,Other locations NOS,Spinal Cord- Lumbar/Thecal Sac,Suprasellar/Hypothalamic/Pituitary",
    "Basal Ganglia,Brain Stem- Midbrain/Tectum,Thalamus,Ventricles",
    "Parietal Lobe,Spinal Cord- Lumbar/Thecal Sac,Temporal Lobe,Thalamus",
    "Spinal Cord- Cervical,Spinal Cord- Thoracic,Temporal Lobe",
    "Brain Stem- Midbrain/Tectum,Occipital Lobe,Temporal Lobe,Thalamus"
]

# CREATE FUNCTION THAT ANNOTATES the data with location (infra, supra, mixed, remove)
def attach_tumour_loc_class(df, data_raw):
    '''
    Takes a df (either the train, valid, or test dataframe), and attaches tumour location to it, using the raw data.
    This function also now filters on only Supra and Infra (because the Mixed were so few), and makes a location label.
    '''
    
    data_raw_location = data_raw[["subjetID", "tumor_location"]].drop_duplicates(subset="subjetID", keep="first")
    df = pd.merge(df, data_raw_location, how="left", left_on="subjetID", right_on="subjetID")

    for i in range(df.shape[0]):
        # Rename Supra
        if df.loc[i, "tumor_location"] in supra_locations:
            df.loc[i, "tumor_location"] = "Supra"

        # Rename Infra
        elif df.loc[i, "tumor_location"] in infra_locations:
            df.loc[i, "tumor_location"] = "Infra"

        # Rename Mixed
        elif df.loc[i, "tumor_location"] in mixed_locations:
            df.loc[i, "tumor_location"] = "Mixed"

        else:
            df.loc[i, "tumor_location"] = "Remove"
    
    # Filter on Supra and Infra
    df = df[df["tumor_location"].isin(["Supra", "Infra"])].copy()


    # Create location label
    converter = {"Supra": 0, "Infra": 1}
    df["loc_label"] = [converter[i] for i in df["tumor_location"]]#df["tumor_location"]

    return df

train_df_loc = attach_tumour_loc_class(train_df, data_raw)
valid_df_loc = attach_tumour_loc_class(valid_df, data_raw)
test_df_loc = attach_tumour_loc_class(test_df, data_raw)


#%%
# Create function that attaches age and sex
def attach_age_gender(df, data_raw):

    # Create dict with patient age at first scan
    subj_survival = data_raw.groupby("subjetID", as_index=False)["survival"].min()
    #subj_survival = {id: surv for id, surv in zip(subj_survival["subjetID"], subj_survival["survival"])}

    # Create dict with patient gender (sex?)
    subj_gender = data_raw.drop_duplicates(subset="subjetID", keep="first")[["subjetID", "gender"]]
    #subj_gender = {id: gender for id, gender in zip(subj_gender["subjetID"], subj_gender["gender"])}
    

    df = pd.merge(df, subj_survival, how="left", left_on="subjetID", right_on="subjetID").copy()
    df = pd.merge(df, subj_gender, how="left", left_on="subjetID", right_on="subjetID").copy()
    
    # Create integer labels
    converter_gend = {"Male": 0, "Female": 1, "Not Available": 2}
    df["gender"] = [converter_gend[i] for i in df["gender"]]

    return df

train_df_extra_metrics = attach_age_gender(train_df_loc, data_raw)
valid_df_extra_metrics = attach_age_gender(valid_df_loc, data_raw)
test_df_extra_metrics = attach_age_gender(test_df_loc, data_raw)


#%%
# SAVE THE DATA (WITH ATTACHED META DATA)
data_path = "/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/"
train_df_extra_metrics.to_csv(data_path+"data/train_df_extra_meta.csv")
valid_df_extra_metrics.to_csv(data_path+"data/valid_df_extra_meta.csv")
test_df_extra_metrics.to_csv(data_path+"data/test_df_extra_meta.csv")



#%%
# SETUP PCA Plots
import torch
import os

os.chdir("/home/simjo484/master_thesis/Master_Thesis")
from utils import EmbedSwinUNETR, get_loader

os.chdir("/home/simjo484/master_thesis/Master_Thesis/BSF_finetuning")
#from bsf_data_utils import get_loader


import matplotlib.pyplot as plt
import argparse

from itertools import islice

import numpy as np

# Arguments
class Args(argparse.Namespace):
    logdir = ""
    optim_lr = 1e-4
    reg_weight = 1e-5
    roi_x = 128
    roi_y = 128
    roi_z = 128
    distributed = False
    workers = 18
    data_dir='/local/data2/simjo484/BRATScommon/BRATS21/'
    json_list = "./jsons/brats21_folds.json"
    fold = 4
    test_mode = False
    batch_size = 1
    debug_mode = False
    device = "cuda"
    cl_device = "cuda"
    pp_device = "cpu"
    data_aug_prob = 0.3

args = Args()

# Data (Brats at first)


#%%
# LOAD MODEL
sequences = "t2" #"t1gd_and_t2"
label_column = "loc_label"

if sequences == "t2":
    # T2W Loader
    loader, loss = get_loader(args, seed = 82734,
                              label_column = label_column, seq_types="T2W", dataset_paths=["/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/data/train_df_extra_meta.csv", "/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/data/valid_df_extra_meta.csv"])

    # T2W Model
    model = EmbedSwinUNETR()
    model.to("cuda")
    model.load_state_dict(torch.load("/local/data2/simjo484/Training_outputs/BSF_finetuning/runs/2025-03-27-13:20:53 (t2)/model_final.pt", map_location="cuda")["state_dict"])
    model.eval()
elif sequences == "t1gd":
    # T1W-GD Loader
    loader, loss = get_loader(args, seed = 82734,
                              label_column = label_column, seq_types="T1W-GD", dataset_paths=["/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/data/train_df_extra_meta.csv", "/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/data/valid_df_extra_meta.csv"])

    # T1W-GD Model
    model = EmbedSwinUNETR()
    model.to("cuda")
    model.load_state_dict(torch.load("/local/data2/simjo484/Training_outputs/BSF_finetuning/runs_t1gd/2025-04-07-10:40:33/model_final.pt", map_location="cuda")["state_dict"])
    model.eval()
elif sequences == "t1gd_and_t2":
    # T1W-GD and T2W Loader
    loader, loss = get_loader(args, seed = 82734,
                              label_column = label_column, seq_types="T1W-GD_T2W", dataset_paths=["/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/data/train_df_extra_meta.csv", "/home/simjo484/master_thesis/Master_Thesis/visualization/miscellaneous/data/valid_df_extra_meta.csv"])

    # T1W-GD and T2W Model
    model = EmbedSwinUNETR()
    model.to("cuda")
    model.load_state_dict(torch.load("/local/data2/simjo484/Training_outputs/BSF_finetuning/runs_t1gd_and_t2/2025-03-28-23:14:58/model_final.pt", map_location="cuda")["state_dict"])
    model.eval()



# CREATE DATA MATRIX
features = []
labels = []

for id, batch_data in enumerate(loader[0]):
    data, target = batch_data["images"].to(args.device), batch_data["label"].to(args.device)
    #print(f"DATA SHAPE: {data.shape}")

    #data = data[0]
    #print(f"DATA SHAPE: {data.shape}")

    x = model(data)

    batch_size = args.batch_size
    #x = torch.flatten(x)
    x = torch.nn.AvgPool3d((4,4,4))(x).view(batch_size, 768)[0] # The [0] is to remove the 1 in the shape from batch size 1.

    features.append(x.detach().to("cpu"))
    labels.append(target.to("cpu"))

features = np.array(features)
labels = np.array(labels)
print(f"FEATURES HAVE DIMS: {features.shape}")
print(f"LABELS HAVE DIMS: {labels.shape}")

#%%
# CREATE PCA PLOT
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced_features = pca.fit_transform(features)
print(pca.explained_variance_ratio_)

# print(labels)

# for i in range(labels.shape[0]):
#     if labels[i][0] < 0 or labels[i][0] > 36000:
#         labels[i][0] = 7000 # dummy around the average

plt.scatter(x=reduced_features[:,0], y=reduced_features[:,1], c=labels)
plt.xlabel("PC1")
plt.ylabel("PC2")
ax = plt.gca()
#ax.set_aspect("equal")

if sequences == "t2":
    plt.suptitle("Features from T2W images")
    plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/t2_pca_features.png")
if sequences == "t1gd":
    plt.suptitle("Features from T1W-GD images")
    plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/t1gd_pca_features.png")
if sequences == "t1gd_and_t2":
    plt.suptitle("Features from fused T1W-GD and T2W images")
    plt.savefig("/home/simjo484/master_thesis/Master_Thesis/visualization/figures/t1gd_and_t2_pca_features.png")


# scale_factor = 10*pca.explained_variance_
# plt.arrow(0,0,
#           scale_factor[0]*pca.components_[0,0],scale_factor[0]*pca.components_[0,1],
#           width=0.02) # PC1
# plt.arrow(0,0,
#           scale_factor[1]*pca.components_[1,0],scale_factor[1]*pca.components_[1,1],
#           width=0.02) # PC2
plt.show()
# %%
